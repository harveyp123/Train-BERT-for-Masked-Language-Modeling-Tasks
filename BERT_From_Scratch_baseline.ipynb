{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "63t-zlejwag8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cj-YtZF-Oaj",
        "outputId": "2e0c16b3-35e8-468f-e446-b9db99db1f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Jan 16 19:16:00 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA RTX A6000               On  | 00000000:01:00.0 Off |                  Off |\n",
            "| 36%   66C    P2             205W / 300W |  17509MiB / 49140MiB |     55%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA RTX A6000               On  | 00000000:41:00.0 Off |                  Off |\n",
            "| 30%   25C    P8              22W / 300W |      8MiB / 49140MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   2  NVIDIA RTX A6000               On  | 00000000:81:00.0 Off |                  Off |\n",
            "| 30%   26C    P8              20W / 300W |      8MiB / 49140MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   3  NVIDIA RTX A6000               On  | 00000000:C1:00.0 Off |                  Off |\n",
            "| 30%   26C    P8              25W / 300W |      8MiB / 49140MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A     30737      C   python                                    17494MiB |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DFEyI5I7wwqr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jiz22029/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# wiki dataset: https://huggingface.co/datasets/wikipedia\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnwq_H0yxFjR",
        "outputId": "0aab2abb-5e62-49a7-8d11-1c2f2ef91219"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'url', 'title', 'text'],\n",
              "        num_rows: 205328\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N8DwOFm9xnaN"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iYUf1vnDy6xR",
        "outputId": "38336bcc-4fef-4503-d51f-9ea8a82fe83c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A boot is a type of footwear that protects the foot and ankle. Boots are higher and larger than shoes and sandals. Some boots are high enough to protect the calves (lower part of the leg) as well.  Some boots are held on with bootstraps or bootlaces.  Some also have spats or gaiters to keep water out.  Most have a very strong boot sole, the bottom part of a boot.\\n\\nTypes of boots \\n Rain boots (or rubber boots) are made from rubber or plastic. Rain boots protect a person\\'s feet from water and rain. People who work on fishing boats and farmers wear rubber boots to keep their feet dry. People who work in chemical factories wear rubber boots to protect their feet from dangerous chemicals.\\n\\n Winter boots are boots that keep a person\\'s feet warm in cold weather. People in cold countries such as Canada and Sweden wear winter boots during the cold season. Winter boots can be made from many different materials, such as leather, fabric, or plastic. Winter boots are insulated with wool or fur to keep the feet warm. Most winter boots also keep people\\'s feet dry.\\n\\n Work boots (or \"construction boots\") are designed for people who work in construction or factory jobs. Work boots often have a steel toe cover to protect the person\\'s toes. Work boots are usually made of strong leather, to protect the person\\'s foot from sharp objects or dangerous chemicals. Some work boots have a flat piece of steel in the sole to protect the foot from sharp nails. Many countries require construction workers to wear work boots when they are on a construction site.\\n\\n Fashion boots are boots that are worn for style than for protection. Usually the term is used for women\\'s boots. These kind of boots come in many heights, where the top ends at the ankle, the knee, or the thigh. The ones that are tall are usually closed by a zipper or can stretch for putting it on easily. This is because using shoe laces would take time for the taller types.\\n\\nOther websites \\n\\nBasic English 850 words\\nFootwear'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_text = dataset[\"train\"]['text'][39]\n",
        "sample_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iKv35tPuySSa"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQJ5ECQTzDRL",
        "outputId": "d9914613-f01f-43f1-ff05-ac7dc8b287f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'A',\n",
              " 'boot',\n",
              " 'is',\n",
              " 'a',\n",
              " 'type',\n",
              " 'of',\n",
              " 'foot',\n",
              " '##wear',\n",
              " 'that',\n",
              " 'protects',\n",
              " 'the',\n",
              " 'foot',\n",
              " 'and',\n",
              " 'ankle',\n",
              " '.',\n",
              " 'Boots',\n",
              " 'are',\n",
              " 'higher',\n",
              " 'and',\n",
              " 'larger',\n",
              " 'than',\n",
              " 'shoes',\n",
              " 'and',\n",
              " 'sand',\n",
              " '##als',\n",
              " '.',\n",
              " 'Some',\n",
              " 'boots',\n",
              " 'are',\n",
              " 'high',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'protect',\n",
              " 'the',\n",
              " 'ca',\n",
              " '##lves',\n",
              " '(',\n",
              " 'lower',\n",
              " 'part',\n",
              " 'of',\n",
              " 'the',\n",
              " 'leg',\n",
              " ')',\n",
              " 'as',\n",
              " 'well',\n",
              " '.',\n",
              " 'Some',\n",
              " 'boots',\n",
              " 'are',\n",
              " 'held',\n",
              " 'on',\n",
              " 'with',\n",
              " 'boots',\n",
              " '##tra',\n",
              " '##ps',\n",
              " 'or',\n",
              " 'boot',\n",
              " '##lace',\n",
              " '##s',\n",
              " '.',\n",
              " 'Some',\n",
              " 'also',\n",
              " 'have',\n",
              " 'spat',\n",
              " '##s',\n",
              " 'or',\n",
              " 'g',\n",
              " '##ait',\n",
              " '##ers',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'water',\n",
              " 'out',\n",
              " '.',\n",
              " 'Most',\n",
              " 'have',\n",
              " 'a',\n",
              " 'very',\n",
              " 'strong',\n",
              " 'boot',\n",
              " 'sole',\n",
              " ',',\n",
              " 'the',\n",
              " 'bottom',\n",
              " 'part',\n",
              " 'of',\n",
              " 'a',\n",
              " 'boot',\n",
              " '.',\n",
              " 'Type',\n",
              " '##s',\n",
              " 'of',\n",
              " 'boots',\n",
              " 'Rain',\n",
              " 'boots',\n",
              " '(',\n",
              " 'or',\n",
              " 'rubber',\n",
              " 'boots',\n",
              " ')',\n",
              " 'are',\n",
              " 'made',\n",
              " 'from',\n",
              " 'rubber',\n",
              " 'or',\n",
              " 'plastic',\n",
              " '.',\n",
              " 'Rain',\n",
              " 'boots',\n",
              " 'protect',\n",
              " 'a',\n",
              " 'person',\n",
              " \"'\",\n",
              " 's',\n",
              " 'feet',\n",
              " 'from',\n",
              " 'water',\n",
              " 'and',\n",
              " 'rain',\n",
              " '.',\n",
              " 'People',\n",
              " 'who',\n",
              " 'work',\n",
              " 'on',\n",
              " 'fishing',\n",
              " 'boats',\n",
              " 'and',\n",
              " 'farmers',\n",
              " 'wear',\n",
              " 'rubber',\n",
              " 'boots',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'their',\n",
              " 'feet',\n",
              " 'dry',\n",
              " '.',\n",
              " 'People',\n",
              " 'who',\n",
              " 'work',\n",
              " 'in',\n",
              " 'chemical',\n",
              " 'factories',\n",
              " 'wear',\n",
              " 'rubber',\n",
              " 'boots',\n",
              " 'to',\n",
              " 'protect',\n",
              " 'their',\n",
              " 'feet',\n",
              " 'from',\n",
              " 'dangerous',\n",
              " 'chemicals',\n",
              " '.',\n",
              " 'Winter',\n",
              " 'boots',\n",
              " 'are',\n",
              " 'boots',\n",
              " 'that',\n",
              " 'keep',\n",
              " 'a',\n",
              " 'person',\n",
              " \"'\",\n",
              " 's',\n",
              " 'feet',\n",
              " 'warm',\n",
              " 'in',\n",
              " 'cold',\n",
              " 'weather',\n",
              " '.',\n",
              " 'People',\n",
              " 'in',\n",
              " 'cold',\n",
              " 'countries',\n",
              " 'such',\n",
              " 'as',\n",
              " 'Canada',\n",
              " 'and',\n",
              " 'Sweden',\n",
              " 'wear',\n",
              " 'winter',\n",
              " 'boots',\n",
              " 'during',\n",
              " 'the',\n",
              " 'cold',\n",
              " 'season',\n",
              " '.',\n",
              " 'Winter',\n",
              " 'boots',\n",
              " 'can',\n",
              " 'be',\n",
              " 'made',\n",
              " 'from',\n",
              " 'many',\n",
              " 'different',\n",
              " 'materials',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'leather',\n",
              " ',',\n",
              " 'fabric',\n",
              " ',',\n",
              " 'or',\n",
              " 'plastic',\n",
              " '.',\n",
              " 'Winter',\n",
              " 'boots',\n",
              " 'are',\n",
              " 'ins',\n",
              " '##ulated',\n",
              " 'with',\n",
              " 'wool',\n",
              " 'or',\n",
              " 'fur',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'the',\n",
              " 'feet',\n",
              " 'warm',\n",
              " '.',\n",
              " 'Most',\n",
              " 'winter',\n",
              " 'boots',\n",
              " 'also',\n",
              " 'keep',\n",
              " 'people',\n",
              " \"'\",\n",
              " 's',\n",
              " 'feet',\n",
              " 'dry',\n",
              " '.',\n",
              " 'Work',\n",
              " 'boots',\n",
              " '(',\n",
              " 'or',\n",
              " '\"',\n",
              " 'construction',\n",
              " 'boots',\n",
              " '\"',\n",
              " ')',\n",
              " 'are',\n",
              " 'designed',\n",
              " 'for',\n",
              " 'people',\n",
              " 'who',\n",
              " 'work',\n",
              " 'in',\n",
              " 'construction',\n",
              " 'or',\n",
              " 'factory',\n",
              " 'jobs',\n",
              " '.',\n",
              " 'Work',\n",
              " 'boots',\n",
              " 'often',\n",
              " 'have',\n",
              " 'a',\n",
              " 'steel',\n",
              " 'toe',\n",
              " 'cover',\n",
              " 'to',\n",
              " 'protect',\n",
              " 'the',\n",
              " 'person',\n",
              " \"'\",\n",
              " 's',\n",
              " 'toes',\n",
              " '.',\n",
              " 'Work',\n",
              " 'boots',\n",
              " 'are',\n",
              " 'usually',\n",
              " 'made',\n",
              " 'of',\n",
              " 'strong',\n",
              " 'leather',\n",
              " ',',\n",
              " 'to',\n",
              " 'protect',\n",
              " 'the',\n",
              " 'person',\n",
              " \"'\",\n",
              " 's',\n",
              " 'foot',\n",
              " 'from',\n",
              " 'sharp',\n",
              " 'objects',\n",
              " 'or',\n",
              " 'dangerous',\n",
              " 'chemicals',\n",
              " '.',\n",
              " 'Some',\n",
              " 'work',\n",
              " 'boots',\n",
              " 'have',\n",
              " 'a',\n",
              " 'flat',\n",
              " 'piece',\n",
              " 'of',\n",
              " 'steel',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sole',\n",
              " 'to',\n",
              " 'protect',\n",
              " 'the',\n",
              " 'foot',\n",
              " 'from',\n",
              " 'sharp',\n",
              " 'nails',\n",
              " '.',\n",
              " 'Many',\n",
              " 'countries',\n",
              " 'require',\n",
              " 'construction',\n",
              " 'workers',\n",
              " 'to',\n",
              " 'wear',\n",
              " 'work',\n",
              " 'boots',\n",
              " 'when',\n",
              " 'they',\n",
              " 'are',\n",
              " 'on',\n",
              " 'a',\n",
              " 'construction',\n",
              " 'site',\n",
              " '.',\n",
              " 'Fashion',\n",
              " 'boots',\n",
              " 'are',\n",
              " 'boots',\n",
              " 'that',\n",
              " 'are',\n",
              " 'worn',\n",
              " 'for',\n",
              " 'style',\n",
              " 'than',\n",
              " 'for',\n",
              " 'protection',\n",
              " '.',\n",
              " 'Usually',\n",
              " 'the',\n",
              " 'term',\n",
              " 'is',\n",
              " 'used',\n",
              " 'for',\n",
              " 'women',\n",
              " \"'\",\n",
              " 's',\n",
              " 'boots',\n",
              " '.',\n",
              " 'These',\n",
              " 'kind',\n",
              " 'of',\n",
              " 'boots',\n",
              " 'come',\n",
              " 'in',\n",
              " 'many',\n",
              " 'heights',\n",
              " ',',\n",
              " 'where',\n",
              " 'the',\n",
              " 'top',\n",
              " 'ends',\n",
              " 'at',\n",
              " 'the',\n",
              " 'ankle',\n",
              " ',',\n",
              " 'the',\n",
              " 'knee',\n",
              " ',',\n",
              " 'or',\n",
              " 'the',\n",
              " 'thigh',\n",
              " '.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'that',\n",
              " 'are',\n",
              " 'tall',\n",
              " 'are',\n",
              " 'usually',\n",
              " 'closed',\n",
              " 'by',\n",
              " 'a',\n",
              " 'zipper',\n",
              " 'or',\n",
              " 'can',\n",
              " 'stretch',\n",
              " 'for',\n",
              " 'putting',\n",
              " 'it',\n",
              " 'on',\n",
              " 'easily',\n",
              " '.',\n",
              " 'This',\n",
              " 'is',\n",
              " 'because',\n",
              " 'using',\n",
              " 'shoe',\n",
              " 'lace',\n",
              " '##s',\n",
              " 'would',\n",
              " 'take',\n",
              " 'time',\n",
              " 'for',\n",
              " 'the',\n",
              " 'taller',\n",
              " 'types',\n",
              " '.',\n",
              " 'Other',\n",
              " 'websites',\n",
              " 'Basic',\n",
              " 'English',\n",
              " '850',\n",
              " 'words',\n",
              " 'Foot',\n",
              " '##wear',\n",
              " '[SEP]']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = tokenizer(sample_text).input_ids\n",
        "[tokenizer.decode(id) for id in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsFhAgAhzKYq",
        "outputId": "de0c74c2-92c7-4e62-9b91-08b3809b6b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19696324\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertForMaskedLM\n",
        "\n",
        "config = BertConfig(\n",
        "    hidden_size = 384,\n",
        "    vocab_size= tokenizer.vocab_size,\n",
        "    num_hidden_layers = 6,\n",
        "    num_attention_heads = 6,\n",
        "    intermediate_size = 1024,\n",
        "    max_position_embeddings = 256\n",
        ")\n",
        "\n",
        "model = BertForMaskedLM(config=config)\n",
        "print(model.num_parameters()) #10457864"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HgRZPfy4zgMH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XbsjqyRuztp8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from accelerate import Accelerator, DistributedType\n",
        "\n",
        "class LineByLineTextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, raw_datasets, max_length: int):\n",
        "        self.padding = \"max_length\"\n",
        "        self.text_column_name = 'text'\n",
        "        self.max_length = max_length\n",
        "        self.accelerator = Accelerator(gradient_accumulation_steps=1)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        with self.accelerator.main_process_first():\n",
        "            self.tokenized_datasets = raw_datasets.map(\n",
        "                self.tokenize_function,\n",
        "                batched=True,\n",
        "                num_proc=4,\n",
        "                remove_columns=[self.text_column_name],\n",
        "                desc=\"Running tokenizer on dataset line_by_line\",\n",
        "            )\n",
        "            self.tokenized_datasets.set_format('torch',columns=['input_ids'],dtype=torch.long)\n",
        "\n",
        "    def tokenize_function(self,examples):\n",
        "        examples[self.text_column_name] = [\n",
        "            line for line in examples[self.text_column_name] if len(line[0]) > 0 and not line[0].isspace()\n",
        "        ]\n",
        "        return self.tokenizer(\n",
        "            examples[self.text_column_name],\n",
        "            padding=self.padding,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_special_tokens_mask=True,\n",
        "        )\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_datasets)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.tokenized_datasets[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "55dae7413be94ac3bd997c21a317b9b4",
            "a0dcbbac15874073811d152ff8453ef0",
            "44747ed4512c49c59509461930657074",
            "e2bf6de8590945dd9efc45806af8a033",
            "1c68ace2e60a4674be726891466b0e5e",
            "17f0d5ce275a430bbeb5e9f568801b3a",
            "1c1724f8f2ea41818ca59c80e271871b",
            "4fa9d42deb224d0cb710f881a1afe0d6",
            "3e048c376ede4523a11d32c7e3104a10",
            "f19226101c9d464dbbe3674959ad7743",
            "1b41f9d77d614907a01c7155d98d88d4"
          ]
        },
        "id": "3JHNv3g4z0sV",
        "outputId": "7c462a72-6b18-431c-f5f0-3eb5a876017a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running tokenizer on dataset line_by_line (num_proc=4):   3%|▎         | 6000/205328 [00:01<00:54, 3661.31 examples/s]\n"
          ]
        },
        {
          "ename": "ArrowInvalid",
          "evalue": "Column 3 named input_ids expected length 1000 but got length 998",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/jiz22029/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/jiz22029/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/utils/py_utils.py\", line 1377, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"/home/jiz22029/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 3485, in _map_single\n    writer.write_batch(batch)\n  File \"/home/jiz22029/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/arrow_writer.py\", line 559, in write_batch\n    pa_table = pa.Table.from_arrays(arrays, schema=schema)\n  File \"pyarrow/table.pxi\", line 3879, in pyarrow.lib.Table.from_arrays\n  File \"pyarrow/table.pxi\", line 3159, in pyarrow.lib.Table.validate\n  File \"pyarrow/error.pxi\", line 100, in pyarrow.lib.check_status\npyarrow.lib.ArrowInvalid: Column 3 named input_ids expected length 1000 but got length 998\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_dataset_train \u001b[38;5;241m=\u001b[39m \u001b[43mLineByLineTextDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_datasets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# adjust this based on your requrements\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[12], line 14\u001b[0m, in \u001b[0;36mLineByLineTextDataset.__init__\u001b[0;34m(self, tokenizer, raw_datasets, max_length)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mmain_process_first():\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenized_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mraw_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_column_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRunning tokenizer on dataset line_by_line\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenized_datasets\u001b[38;5;241m.\u001b[39mset_format(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/dataset_dict.py:855\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    853\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 855\u001b[0m     {\n\u001b[1;32m    856\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    857\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    858\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[1;32m    859\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[1;32m    860\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[1;32m    861\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    862\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    863\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    864\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[1;32m    865\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    866\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    867\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    868\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    869\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    870\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[1;32m    871\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[1;32m    872\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    873\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    874\u001b[0m         )\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    876\u001b[0m     }\n\u001b[1;32m    877\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/dataset_dict.py:856\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    853\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    855\u001b[0m     {\n\u001b[0;32m--> 856\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    876\u001b[0m     }\n\u001b[1;32m    877\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    554\u001b[0m }\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/arrow_dataset.py:3181\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3174\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   3176\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3177\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3178\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3179\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3180\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   3182\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[1;32m   3183\u001b[0m     ):\n\u001b[1;32m   3184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3185\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/utils/py_utils.py:1417\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m   1416\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1417\u001b[0m         [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/datasets/utils/py_utils.py:1417\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m   1416\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1417\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
            "File \u001b[0;32m~/miniconda3/envs/dpr_llm/lib/python3.9/site-packages/multiprocess/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: Column 3 named input_ids expected length 1000 but got length 998"
          ]
        }
      ],
      "source": [
        "tokenized_dataset_train = LineByLineTextDataset(\n",
        "    tokenizer= tokenizer,\n",
        "    raw_datasets = dataset,\n",
        "    max_length=256, # adjust this based on your requrements\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GIjhaaeMz73W"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model\",\n",
        "    overwrite_output_dir=True,\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=\"Ransaka/sinhala-bert-yt\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    max_steps=500,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    report_to='none',\n",
        "    hub_private_repo = True,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset_train['train'],\n",
        "    eval_dataset= tokenized_dataset_train['train'], # change to your actual evaluation dataset\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "sg9bOHPv0Vw5",
        "outputId": "53da869e-5843-427e-feea-9a66ef715c87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 05:10, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.417200</td>\n",
              "      <td>7.251174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.184500</td>\n",
              "      <td>7.121541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>7.080100</td>\n",
              "      <td>7.046470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>7.040800</td>\n",
              "      <td>7.016527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>7.020600</td>\n",
              "      <td>7.002804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=7.14864013671875, metrics={'train_runtime': 312.1458, 'train_samples_per_second': 102.516, 'train_steps_per_second': 1.602, 'total_flos': 412770186166272.0, 'train_loss': 7.14864013671875, 'epoch': 3.18})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "AOV3jGka3xkI",
        "outputId": "68f51c5a-3ffa-40c4-981f-35fd5e06d0a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [157/157 00:22]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6ovA1Dm_r9v",
        "outputId": "abcbbdc2-0a8e-4d80-98ad-4898eef7f4df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Perplexity: 1102.21\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "print(f\">>> Perplexity: {math.exp(results['eval_loss']):.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17f0d5ce275a430bbeb5e9f568801b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b41f9d77d614907a01c7155d98d88d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1724f8f2ea41818ca59c80e271871b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c68ace2e60a4674be726891466b0e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e048c376ede4523a11d32c7e3104a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44747ed4512c49c59509461930657074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fa9d42deb224d0cb710f881a1afe0d6",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e048c376ede4523a11d32c7e3104a10",
            "value": 10000
          }
        },
        "4fa9d42deb224d0cb710f881a1afe0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55dae7413be94ac3bd997c21a317b9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0dcbbac15874073811d152ff8453ef0",
              "IPY_MODEL_44747ed4512c49c59509461930657074",
              "IPY_MODEL_e2bf6de8590945dd9efc45806af8a033"
            ],
            "layout": "IPY_MODEL_1c68ace2e60a4674be726891466b0e5e"
          }
        },
        "a0dcbbac15874073811d152ff8453ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f0d5ce275a430bbeb5e9f568801b3a",
            "placeholder": "​",
            "style": "IPY_MODEL_1c1724f8f2ea41818ca59c80e271871b",
            "value": "Running tokenizer on dataset line_by_line (num_proc=4): 100%"
          }
        },
        "e2bf6de8590945dd9efc45806af8a033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f19226101c9d464dbbe3674959ad7743",
            "placeholder": "​",
            "style": "IPY_MODEL_1b41f9d77d614907a01c7155d98d88d4",
            "value": " 10000/10000 [00:05&lt;00:00, 2510.33 examples/s]"
          }
        },
        "f19226101c9d464dbbe3674959ad7743": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
